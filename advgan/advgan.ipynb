{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow2.0.0a0\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# pip install PIL\n",
    "# import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "    \n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input is picture x\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5,5), strides=(2,2), padding='same', use_bias=False,\n",
    "                            input_shape=[28,28,1]))\n",
    "    assert model.output_shape == (None,14,14,64) # Note:None is the size of batch\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same', use_bias=False,\n",
    "                            input_shape=[28,28,1]))\n",
    "    assert model.output_shape == (None, 7 ,7 ,128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())    \n",
    "    \n",
    "    model.add(layers.Conv2D(256, (5,5), strides=(1,1), padding='same', use_bias=False,\n",
    "                            input_shape=[28,28,1]))\n",
    "    assert model.output_shape == (None, 7 ,7 ,256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())    \n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# the input is noise\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d513cb43c8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "x = train_images[1]\n",
    "generated_image = generator(x.reshape(1,28,28,1), training=False)\n",
    "generated_image\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00080696]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dis loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gen loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(images, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    wxz_i = 1\n",
    "    for image_batch in dataset:\n",
    "      print(wxz_i)\n",
    "      train_step(image_batch)\n",
    "      wxz_i = wxz_i + 1\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-d152560ca122>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-87cee32ba845>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m       \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwxz_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m       \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m       \u001b[0mwxz_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwxz_i\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    412\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m     \"\"\"\n\u001b[0;32m    573\u001b[0m     return self._call_flat(\n\u001b[1;32m--> 574\u001b[1;33m         (t for t in nest.flatten((args, kwargs))\n\u001b[0m\u001b[0;32m    575\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m    576\u001b[0m                            resource_variable_ops.ResourceVariable))))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[0;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[1;32m--> 415\u001b[1;33m             ctx=ctx)\n\u001b[0m\u001b[0;32m    416\u001b[0m       \u001b[1;31m# Replace empty list with None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
